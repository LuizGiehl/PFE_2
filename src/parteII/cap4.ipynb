{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CAPÍTULO 4 \n",
    "-\n",
    "Preparação de dados\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2 Tidy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - Cada linha é uma observação (observation)\n",
    "\n",
    "    - Cada coluna é uma variável (variable)\n",
    "\n",
    "    - Cada tipo de unidade de pbservação forma uma tabela"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.2.1 Combinando conjuntos de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algo muito nescessário é juntar conjuntos de dados para responder alguma pergunta. Se você quer descobrir o preço das ações de uma empresa, mas as informações das empresas estão em uma tebela e as das ações em outras, é preciso que você junte as duas para descobrir e analisar o preço que cada uma tem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3 Concatenação\n",
    "\n",
    "Uma das maeniras mais (conceitualmente) fáceis de combinar dados é por meio da concatenação\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3.1 Adicionando linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3 \n",
      "\n",
      "    A   B   C   D\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7 \n",
      "\n",
      "     A    B    C    D\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv('../../data/concat_1.csv')\n",
    "df2 = pd.read_csv('../../data/concat_2.csv')\n",
    "df3 = pd.read_csv('../../data/concat_3.csv')\n",
    "\n",
    "print(df1, '\\n')\n",
    "print(df2, '\\n')\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D\n",
      "0   a0   b0   c0   d0\n",
      "1   a1   b1   c1   d1\n",
      "2   a2   b2   c2   d2\n",
      "3   a3   b3   c3   d3\n",
      "0   a4   b4   c4   d4\n",
      "1   a5   b5   c5   d5\n",
      "2   a6   b6   c6   d6\n",
      "3   a7   b7   c7   d7\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "#concatena as listas\n",
    "row_concat = pd.concat([df1, df2, df3])\n",
    "print(row_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "podemos ver que concat empilha cegamente os dataframes, mantendo os nomes das linhas e apenas as empilhando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    a3\n",
      "B    b3\n",
      "C    c3\n",
      "D    d3\n",
      "Name: 3, dtype: object \n",
      "\n",
      "     A    B    C    D\n",
      "3   a3   b3   c3   d3\n",
      "3   a7   b7   c7   d7\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(row_concat.iloc[3, ], '\\n')\n",
    "\n",
    "print(row_concat.loc[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se usarmos o loc para obter um subconjunto ele irá pegar todas as linhas do mesmo nome.\n",
    "\n",
    "Mas usando iloc ele pega apenas uma linha com o índice, o que indica que os índices mudam, mas apenas mantém o nome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se criar uma nova Serie e concatenar com um dataframe, ela será concatenada corretamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    n1\n",
      "1    n2\n",
      "2    n3\n",
      "3    n4\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "new_row_series = pd.Series(['n1', 'n2', 'n3', 'n4'])\n",
    "print(new_row_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    0\n",
      "0   a0   b0   c0   d0  NaN\n",
      "1   a1   b1   c1   d1  NaN\n",
      "2   a2   b2   c2   d2  NaN\n",
      "3   a3   b3   c3   d3  NaN\n",
      "0  NaN  NaN  NaN  NaN   n1\n",
      "1  NaN  NaN  NaN  NaN   n2\n",
      "2  NaN  NaN  NaN  NaN   n3\n",
      "3  NaN  NaN  NaN  NaN   n4\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, new_row_series]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver isso precisamos transformar o series em um dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "new_row_df = pd.DataFrame([['n1','n2','n3','n4']],\n",
    "                          columns=['A','B','C','D'])\n",
    "print(new_row_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, new_row_df]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concat é uma função genérica que concatena vários dados de uma só vez.\n",
    "\n",
    "Para concatenar apenas um objeto se usava a função append, mas ela já está obsoleta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1, df2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3\n",
      "4  n1  n2  n3  n4\n"
     ]
    }
   ],
   "source": [
    "data_dict = {'A': 'n1',\n",
    "             'B': 'n2',\n",
    "             'C': 'n3',\n",
    "             'D': 'n4'}\n",
    "\n",
    "df_dict = pd.DataFrame(data_dict, index=[0])\n",
    "\n",
    "print(pd.concat([df1, df_dict], ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para concatenar um dict com um dataframe é preciso converter o dict para dataframe,  \n",
    "e caso o dict tenha valores escalares (ou seja, valores que não são listas) você precisa passar um index para o dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3.1.1 Ignorando o índice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se quisermos concatenar dados podemos passar o parâmetro ignore_index para reiniciar o índice das linhas depois de concatenar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A    B    C    D\n",
      "0    a0   b0   c0   d0\n",
      "1    a1   b1   c1   d1\n",
      "2    a2   b2   c2   d2\n",
      "3    a3   b3   c3   d3\n",
      "4    a4   b4   c4   d4\n",
      "5    a5   b5   c5   d5\n",
      "6    a6   b6   c6   d6\n",
      "7    a7   b7   c7   d7\n",
      "8    a8   b8   c8   d8\n",
      "9    a9   b9   c9   d9\n",
      "10  a10  b10  c10  d10\n",
      "11  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat_i = pd.concat([df1, df2, df3], ignore_index=True)\n",
    "\n",
    "print(row_concat_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3.2 Adicionando colunas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenar colunas é igualmente facíl a concatenar linhas, basta passarmos o parâmetro axis. \n",
    "Por padrão axis vem com valor 0, o que faz que concatene nas linhas, mas se passar 1 ela irá concatenar em colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "col_concat = pd.concat([df1, df2, df3], axis=1)\n",
    "\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   A    A\n",
      "0  a0  a4   a8\n",
      "1  a1  a5   a9\n",
      "2  a2  a6  a10\n",
      "3  a3  a7  a11\n"
     ]
    }
   ],
   "source": [
    "print(col_concat['A'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se gerarmos um subconjunto pelo nome da coluna, iremos obter todas as colunas com mesmo nome"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para adicionar uma nova coluna não é nescessário uma função, basta especificar o nome da coluna e seu vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D new_col_list\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8           n1\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9           n2\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10           n3\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11           n4\n"
     ]
    }
   ],
   "source": [
    "col_concat['new_col_list'] = ['n1','n2','n3','n4']\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   B   C   D    A    B    C    D new_col_list  \\\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8           n1   \n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9           n2   \n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10           n3   \n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11           n4   \n",
      "\n",
      "  new_col_series  \n",
      "0             n1  \n",
      "1             n2  \n",
      "2             n3  \n",
      "3             n4  \n"
     ]
    }
   ],
   "source": [
    "col_concat['new_col_series'] = pd.Series(['n1','n2','n3','n4'])\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Também é possível reiniciar os índices das colunas para que não tenhamos nomes duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0   1   2   3   4   5   6   7    8    9    10   11\n",
      "0  a0  b0  c0  d0  a4  b4  c4  d4   a8   b8   c8   d8\n",
      "1  a1  b1  c1  d1  a5  b5  c5  d5   a9   b9   c9   d9\n",
      "2  a2  b2  c2  d2  a6  b6  c6  d6  a10  b10  c10  d10\n",
      "3  a3  b3  c3  d3  a7  b7  c7  d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1,df2,df3], axis=1, ignore_index=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3.3 Concatenação com índices diferentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3.3.1 Concatenando linhas com colunas diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3 \n",
      "\n",
      "    E   F   G   H\n",
      "0  a4  b4  c4  d4\n",
      "1  a5  b5  c5  d5\n",
      "2  a6  b6  c6  d6\n",
      "3  a7  b7  c7  d7 \n",
      "\n",
      "     A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "1   a9   b9   c9   d9\n",
      "2  a10  b10  c10  d10\n",
      "3  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "# .columns é um parâmetro para passar novas ou renomear as colunas já existentes para um dataframe\n",
    "df1.columns = ['A','B','C','D']\n",
    "df2.columns = ['E', 'F', 'G', 'H']\n",
    "df3.columns = ['A', 'C', 'F', 'H']\n",
    "\n",
    "print(df1, '\\n')\n",
    "print(df2, '\\n')\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN\n",
      "0  NaN  NaN  NaN  NaN   a4   b4   c4   d4\n",
      "1  NaN  NaN  NaN  NaN   a5   b5   c5   d5\n",
      "2  NaN  NaN  NaN  NaN   a6   b6   c6   d6\n",
      "3  NaN  NaN  NaN  NaN   a7   b7   c7   d7\n",
      "0   a8  NaN   b8  NaN  NaN   c8  NaN   d8\n",
      "1   a9  NaN   b9  NaN  NaN   c9  NaN   d9\n",
      "2  a10  NaN  b10  NaN  NaN  c10  NaN  d10\n",
      "3  a11  NaN  b11  NaN  NaN  c11  NaN  d11\n"
     ]
    }
   ],
   "source": [
    "row_concat = pd.concat([df1,df2,df3])\n",
    "print(row_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma maneira para remover os valores NaN é passando o parâmetro join. Esse parâmetro mantem somente as colunas que são compartilhadas entre o conjunto de dados.  \n",
    "Ele vem por padrão como 'outer' que mantem todas as colunas, mas se passarmos 'inner' ele mantem apenas as compartilhadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 0, 1, 2, 3, 0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1,df2,df3], join='inner'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    C\n",
      "0   a0   c0\n",
      "1   a1   c1\n",
      "2   a2   c2\n",
      "3   a3   c3\n",
      "0   a8   b8\n",
      "1   a9   b9\n",
      "2  a10  b10\n",
      "3  a11  b11\n"
     ]
    }
   ],
   "source": [
    "#se passarmos dois que tenham colunas em comum somente as que são compartilhdas serão devolvidas\n",
    "print(pd.concat([df1,df3], join='inner', ignore_index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.3.3.2 Concatenando colunas com linhas diferentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D\n",
      "0  a0  b0  c0  d0\n",
      "1  a1  b1  c1  d1\n",
      "2  a2  b2  c2  d2\n",
      "3  a3  b3  c3  d3 \n",
      "\n",
      "    E   F   G   H\n",
      "4  a4  b4  c4  d4\n",
      "5  a5  b5  c5  d5\n",
      "6  a6  b6  c6  d6\n",
      "7  a7  b7  c7  d7 \n",
      "\n",
      "     A    C    F    H\n",
      "0   a8   b8   c8   d8\n",
      "2   a9   b9   c9   d9\n",
      "5  a10  b10  c10  d10\n",
      "7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "#modificando os  índices\n",
    "df1.index = [0,1,2,3]\n",
    "df2.index = [4,5,6,7]\n",
    "df3.index = [0,2,5,7]\n",
    "\n",
    "\n",
    "print(df1, '\\n')\n",
    "print(df2, '\\n')\n",
    "print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     A    B    C    D    E    F    G    H    A    C    F    H\n",
      "0   a0   b0   c0   d0  NaN  NaN  NaN  NaN   a8   b8   c8   d8\n",
      "1   a1   b1   c1   d1  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "2   a2   b2   c2   d2  NaN  NaN  NaN  NaN   a9   b9   c9   d9\n",
      "3   a3   b3   c3   d3  NaN  NaN  NaN  NaN  NaN  NaN  NaN  NaN\n",
      "4  NaN  NaN  NaN  NaN   a4   b4   c4   d4  NaN  NaN  NaN  NaN\n",
      "5  NaN  NaN  NaN  NaN   a5   b5   c5   d5  a10  b10  c10  d10\n",
      "6  NaN  NaN  NaN  NaN   a6   b6   c6   d6  NaN  NaN  NaN  NaN\n",
      "7  NaN  NaN  NaN  NaN   a7   b7   c7   d7  a11  b11  c11  d11\n"
     ]
    }
   ],
   "source": [
    "col_concat = pd.concat([df1,df2,df3], axis=1)\n",
    "print(col_concat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assim como na concatenação por linha, podemos optar por manter um resultado apenas quando houver índices correnpondentes usando join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    A   B   C   D   A   C   F   H\n",
      "0  a0  b0  c0  d0  a8  b8  c8  d8\n",
      "2  a2  b2  c2  d2  a9  b9  c9  d9\n"
     ]
    }
   ],
   "source": [
    "print(pd.concat([df1,df3], join='inner', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4 Combinando vários conjuntos de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem duas formas de unir dados, uma é usando 'marge' e outra usando 'join'.  \n",
    "marge é mais flexível e permite fazer junções (joins) baseadas em colunas comum entre dataframes.  \n",
    "Já join é principalmente usado para unir dataframes baseado nos índices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ident   personal    family\n",
      "0      dyer    William      Dyer\n",
      "1        pb      Frank   Pabodie\n",
      "2      lake   Anderson      Lake\n",
      "3       roe  Valentina   Roerich\n",
      "4  danforth      Frank  Danforth \n",
      "\n",
      "    name    lat    long\n",
      "0   DR-1 -49.85 -128.57\n",
      "1   DR-3 -47.15 -126.72\n",
      "2  MSK-4 -48.87 -123.40 \n",
      "\n",
      "    taken person quant  reading\n",
      "0     619   dyer   rad     9.82\n",
      "1     619   dyer   sal     0.13\n",
      "2     622   dyer   rad     7.80\n",
      "3     622   dyer   sal     0.09\n",
      "4     734     pb   rad     8.41\n",
      "5     734   lake   sal     0.05\n",
      "6     734     pb  temp   -21.50\n",
      "7     735     pb   rad     7.22\n",
      "8     735    NaN   sal     0.06\n",
      "9     735    NaN  temp   -26.00\n",
      "10    751     pb   rad     4.35\n",
      "11    751     pb  temp   -18.50\n",
      "12    751   lake   sal     0.10\n",
      "13    752   lake   rad     2.19\n",
      "14    752   lake   sal     0.09\n",
      "15    752   lake  temp   -16.00\n",
      "16    752    roe   sal    41.60\n",
      "17    837   lake   rad     1.46\n",
      "18    837   lake   sal     0.21\n",
      "19    837    roe   sal    22.50\n",
      "20    844    roe   rad    11.25 \n",
      "\n",
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "1    622   DR-1  1927-02-10\n",
      "2    734   DR-3  1939-01-07\n",
      "3    735   DR-3  1930-01-12\n",
      "4    751   DR-3  1930-02-26\n",
      "5    752   DR-3         NaN\n",
      "6    837  MSK-4  1932-01-14\n",
      "7    844   DR-1  1932-03-22 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "person = pd.read_csv('../../data/survey_person.csv')\n",
    "site = pd.read_csv('../../data/survey_site.csv')\n",
    "survey = pd.read_csv('../../data/survey_survey.csv')\n",
    "visited = pd.read_csv('../../data/survey_visited.csv')\n",
    "\n",
    "print(person, '\\n')\n",
    "print(site, '\\n')\n",
    "print(survey, '\\n')\n",
    "print(visited, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.1 Merge um a um"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No tipo mais simples de marge temos dois dataframes que queremos fazer a junção das colunas e que não contêm valores duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   site       dated\n",
      "0    619   DR-1  1927-02-08\n",
      "2    734   DR-3  1939-01-07\n",
      "6    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "#modificaremos o dataframe visited para não haver valores duplicados de site\n",
    "visited_subset = visited.loc[[0,2,6], ]\n",
    "\n",
    "print(visited_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos fazer o marge um a um (one-to-one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "2  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "#valor default de 'how' é 'inner', e não precisa ser especificado\n",
    "o2o_merge = site.merge(visited_subset, left_on='name', right_on='site')\n",
    "\n",
    "print(o2o_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No jargão SQL as colunas usadas na correspondência são chamadas de \"chaves\". Neste caso as colunas name e site que possue os valores correspondentes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.2 Merge de muitos para um (many-to-one)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse tipo de merge um dos dataframes tem valores chaves que se repetem, e os dataframes que possuem observações únicas serão então duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    name    lat    long  ident   site       dated\n",
      "0   DR-1 -49.85 -128.57    619   DR-1  1927-02-08\n",
      "1   DR-1 -49.85 -128.57    622   DR-1  1927-02-10\n",
      "2   DR-1 -49.85 -128.57    844   DR-1  1932-03-22\n",
      "3   DR-3 -47.15 -126.72    734   DR-3  1939-01-07\n",
      "4   DR-3 -47.15 -126.72    735   DR-3  1930-01-12\n",
      "5   DR-3 -47.15 -126.72    751   DR-3  1930-02-26\n",
      "6   DR-3 -47.15 -126.72    752   DR-3         NaN\n",
      "7  MSK-4 -48.87 -123.40    837  MSK-4  1932-01-14\n"
     ]
    }
   ],
   "source": [
    "m2o_merge = site.merge(visited, left_on='name', right_on='site')\n",
    "\n",
    "print(m2o_merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.4.3 Merge de Todos para Todos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident   personal   family  taken person quant  reading\n",
      "0   dyer    William     Dyer    619   dyer   rad     9.82\n",
      "1   dyer    William     Dyer    619   dyer   sal     0.13\n",
      "2   dyer    William     Dyer    622   dyer   rad     7.80\n",
      "3   dyer    William     Dyer    622   dyer   sal     0.09\n",
      "4     pb      Frank  Pabodie    734     pb   rad     8.41\n",
      "5     pb      Frank  Pabodie    734     pb  temp   -21.50\n",
      "6     pb      Frank  Pabodie    735     pb   rad     7.22\n",
      "7     pb      Frank  Pabodie    751     pb   rad     4.35\n",
      "8     pb      Frank  Pabodie    751     pb  temp   -18.50\n",
      "9   lake   Anderson     Lake    734   lake   sal     0.05\n",
      "10  lake   Anderson     Lake    751   lake   sal     0.10\n",
      "11  lake   Anderson     Lake    752   lake   rad     2.19\n",
      "12  lake   Anderson     Lake    752   lake   sal     0.09\n",
      "13  lake   Anderson     Lake    752   lake  temp   -16.00\n",
      "14  lake   Anderson     Lake    837   lake   rad     1.46\n",
      "15  lake   Anderson     Lake    837   lake   sal     0.21\n",
      "16   roe  Valentina  Roerich    752    roe   sal    41.60\n",
      "17   roe  Valentina  Roerich    837    roe   sal    22.50\n",
      "18   roe  Valentina  Roerich    844    roe   rad    11.25 \n",
      "\n",
      "    ident   site       dated  taken person quant  reading\n",
      "0     619   DR-1  1927-02-08    619   dyer   rad     9.82\n",
      "1     619   DR-1  1927-02-08    619   dyer   sal     0.13\n",
      "2     622   DR-1  1927-02-10    622   dyer   rad     7.80\n",
      "3     622   DR-1  1927-02-10    622   dyer   sal     0.09\n",
      "4     734   DR-3  1939-01-07    734     pb   rad     8.41\n",
      "5     734   DR-3  1939-01-07    734   lake   sal     0.05\n",
      "6     734   DR-3  1939-01-07    734     pb  temp   -21.50\n",
      "7     735   DR-3  1930-01-12    735     pb   rad     7.22\n",
      "8     735   DR-3  1930-01-12    735    NaN   sal     0.06\n",
      "9     735   DR-3  1930-01-12    735    NaN  temp   -26.00\n",
      "10    751   DR-3  1930-02-26    751     pb   rad     4.35\n",
      "11    751   DR-3  1930-02-26    751     pb  temp   -18.50\n",
      "12    751   DR-3  1930-02-26    751   lake   sal     0.10\n",
      "13    752   DR-3         NaN    752   lake   rad     2.19\n",
      "14    752   DR-3         NaN    752   lake   sal     0.09\n",
      "15    752   DR-3         NaN    752   lake  temp   -16.00\n",
      "16    752   DR-3         NaN    752    roe   sal    41.60\n",
      "17    837  MSK-4  1932-01-14    837   lake   rad     1.46\n",
      "18    837  MSK-4  1932-01-14    837   lake   sal     0.21\n",
      "19    837  MSK-4  1932-01-14    837    roe   sal    22.50\n",
      "20    844   DR-1  1932-03-22    844    roe   rad    11.25\n"
     ]
    }
   ],
   "source": [
    "ps = person.merge(survey, left_on='ident', right_on='person')\n",
    "vs = visited.merge(survey, left_on='ident', right_on='taken')\n",
    "\n",
    "print(ps, '\\n')\n",
    "print(vs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos executar um merge de muitos para muitos passando as várias colunas com as quais a correspondência será feita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ident_x   personal   family  taken_x person_x quant  reading  ident_y  \\\n",
      "0     dyer    William     Dyer      619     dyer   rad     9.82      619   \n",
      "1     dyer    William     Dyer      619     dyer   sal     0.13      619   \n",
      "2     dyer    William     Dyer      622     dyer   rad     7.80      622   \n",
      "3     dyer    William     Dyer      622     dyer   sal     0.09      622   \n",
      "4       pb      Frank  Pabodie      734       pb   rad     8.41      734   \n",
      "5       pb      Frank  Pabodie      734       pb  temp   -21.50      734   \n",
      "6       pb      Frank  Pabodie      735       pb   rad     7.22      735   \n",
      "7       pb      Frank  Pabodie      751       pb   rad     4.35      751   \n",
      "8       pb      Frank  Pabodie      751       pb  temp   -18.50      751   \n",
      "9     lake   Anderson     Lake      734     lake   sal     0.05      734   \n",
      "10    lake   Anderson     Lake      751     lake   sal     0.10      751   \n",
      "11    lake   Anderson     Lake      752     lake   rad     2.19      752   \n",
      "12    lake   Anderson     Lake      752     lake   sal     0.09      752   \n",
      "13    lake   Anderson     Lake      752     lake  temp   -16.00      752   \n",
      "14    lake   Anderson     Lake      837     lake   rad     1.46      837   \n",
      "15    lake   Anderson     Lake      837     lake   sal     0.21      837   \n",
      "16     roe  Valentina  Roerich      752      roe   sal    41.60      752   \n",
      "17     roe  Valentina  Roerich      837      roe   sal    22.50      837   \n",
      "18     roe  Valentina  Roerich      844      roe   rad    11.25      844   \n",
      "\n",
      "     site       dated  taken_y person_y  \n",
      "0    DR-1  1927-02-08      619     dyer  \n",
      "1    DR-1  1927-02-08      619     dyer  \n",
      "2    DR-1  1927-02-10      622     dyer  \n",
      "3    DR-1  1927-02-10      622     dyer  \n",
      "4    DR-3  1939-01-07      734       pb  \n",
      "5    DR-3  1939-01-07      734       pb  \n",
      "6    DR-3  1930-01-12      735       pb  \n",
      "7    DR-3  1930-02-26      751       pb  \n",
      "8    DR-3  1930-02-26      751       pb  \n",
      "9    DR-3  1939-01-07      734     lake  \n",
      "10   DR-3  1930-02-26      751     lake  \n",
      "11   DR-3         NaN      752     lake  \n",
      "12   DR-3         NaN      752     lake  \n",
      "13   DR-3         NaN      752     lake  \n",
      "14  MSK-4  1932-01-14      837     lake  \n",
      "15  MSK-4  1932-01-14      837     lake  \n",
      "16   DR-3         NaN      752      roe  \n",
      "17  MSK-4  1932-01-14      837      roe  \n",
      "18   DR-1  1932-03-22      844      roe   \n",
      "\n",
      "ident_x           dyer\n",
      "personal       William\n",
      "family            Dyer\n",
      "taken_x            619\n",
      "person_x          dyer\n",
      "quant              rad\n",
      "reading           9.82\n",
      "ident_y            619\n",
      "site              DR-1\n",
      "dated       1927-02-08\n",
      "taken_y            619\n",
      "person_y          dyer\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ps_vs = ps.merge(vs,\n",
    "                 left_on=['ident', 'taken', 'quant', 'reading'],\n",
    "                 right_on=['person', 'ident', 'quant', 'reading'])\n",
    "print(ps_vs, '\\n')\n",
    "print(ps_vs.loc[0, ])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfe_certo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
